# README for 210208_imputation
The premise of this analysis was that we could:
1. Select a subset of the 919 individuals with the least amount of missing data and impute them with BEAGLE vesion 5.
2. Use the imputed dataset to serve as a reference panel for the remainder of the dataset.

There were some minor issues with formatting. Notably, the genotype allele separator in the VCF files is the forward slash (/), but the BEAGLE output separates the genotype alleles with the pipe symbol (|). It also lacks other output that is present in a typical VCF file like the depth of the variant, etc which are separated by a colon (:).  The [reformat_imputed_vcf.sh](reformat_imputed_vcf.sh) script was written to turn the pipe back to the foward slash so that the [normalize.awk](normalize.awk) script would work. The [normalize.awk](normalize.awk) script was also modified so that the genotype field (GT) would be written to the output because it didn't initially work like the original because of the absence of the other fields.

## Imputing with a reference panel
The script [filter_with_vcftools_by_snp_pos.sh](filter_with_vcftools_by_snp_pos.sh) was used to filter the VCF files by position. We were going to try using the SNP ID that we added using the Add_ID_to_VCF.py script, but the count starts from 0 at the beginning of each scaffold/chromosome, so there are some duplicates. As a result, I think it's better to use the combination of scaffold name + position (in basepairs) to filter. The positions to keep are located in the [snp_pos_to_keep.txt](snp_pos_to_keep.txt) file. The script [run_normalize_awk_for_filtered_imputed.sh](run_normalize_awk_for_filtered_imputed.sh) uses the AWK script [normalize_modified_for_imputed_snps.awk](normalize_modified_for_imputed_snps.awk) to convert the imputed VCF files into a TSV file. The script [run_filter_snps_and_make_wide_format_by_snp_pos.sh](run_filter_snps_and_make_wide_format_by_snp_pos.sh) then launches the R script [filter_snps_and_make_wide_format.R](filter_snps_and_make_wide_format.R) to convert the TSV file into a CSV file which can be used for downstream analyses (e.g., GWAS).

I created the PCA plots using PLINK. This happens in essentially two steps. First, the script [run_plink_imputed_filt_by_snp_pos.sh](run_plink_imputed_filt_by_snp_pos.sh) converts the VCF files into PLINK format. Please note: they were concatenated into a single file using ```bcftools concat``` prior to launching the PLINK script. The second step reads the output from PLINK (eigenval and eigenvec files) into R and produces the PCA plot (in a PDF file). The shell script is [run_plot_plink_pca.sh](run_plot_plink_pca.sh) which uses the R script [plot_plink_pca.R](plot_plink_pca.R). In addition to the PCA plots in the PDF file, the data are saved in an Rdata file.

The script [impute_with_beagle_with_ref_and_filt_by_snp_pos.sh](impute_with_beagle_with_ref_and_filt_by_snp_pos.sh) was used to impute with a reference panel. The reference panel was selected based on having the least amount of missing data and was independently imputed before being used as a reference panel because BEAGLE won't permit any missing data in the reference panel. After imputation, the [reformat_imputed_vcf_filt_by_pos.sh](reformat_imputed_vcf_filt_by_pos.sh) script was used to replace the pipe character "|" with the forward slash "/" as described above.

## Imputing without a reference panel

The scripts [run_plink_imputed_no_ref_filt_by_snp_pos.sh](run_plink_imputed_no_ref_filt_by_snp_pos.sh) and [plot_plink_pca_imputed_no_ref_filt_by_snp_pos.sh](plot_plink_pca_imputed_no_ref_filt_by_snp_pos.sh) were initially run (after converting the merged VCF file for the dataset imputed _without_ a reference panel) and the PCA plots were very different than expected. The samples were all highly compressed along the first 3 principal components. As it turns out, a single sample (Sample_0975 aka K2EF-C16) was the cause of the distortion. Removal of this sample using the ```--remove``` option of PLINK (with the file  [sample_to_remove_from_plink.txt](sample_to_remove_from_plink.txt) resulted in plots that more closely match our expectations based on what the PCA plots looked like prior to imputation. The scripts used for that process were [run_plink_imputed_no_ref_filt_by_snp_pos_outlier_removed.sh](run_plink_imputed_no_ref_filt_by_snp_pos_outlier_removed.sh) and [plot_plink_pca_imputed_no_ref_filt_by_snp_pos_outlier_removed.sh](plot_plink_pca_imputed_no_ref_filt_by_snp_pos_outlier_removed.sh). Please note the name of the sample in [sample_to_remove_from_plink.txt](sample_to_remove_from_plink.txt) follows a slightly more complex nomenclature method than just "Sample_0975", presumably because of how they appear in the VCF files (```Sample_0975/Sample_0975_sorted.bam```). It's also repeated in a second column.
